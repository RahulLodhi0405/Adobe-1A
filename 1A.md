# Multilingual PDF Outline and Table Extractor

## Overview

This is a Python application that extracts structured outlines and table data from PDF files with comprehensive Unicode support for all languages, including RTL scripts (Arabic, Hebrew) and CJK languages (Chinese, Japanese, Korean). The system processes PDFs quickly (under 10 seconds per file) and supports batch processing from input directories.

**NEW: Full Docker containerization support added for deployment in CPU-only environments without internet access, meeting all specified requirements for the structured PDF outline extractor.**

## User Preferences

Preferred communication style: Simple, everyday language.

## System Architecture

### Core Architecture
The application follows a modular design pattern with separate components for different extraction tasks:

- **Main Entry Point** (`main.py`): Handles command-line interface, directory validation, and orchestrates the processing workflow
- **PDF Processor** (`pdf_processor.py`): Central coordinator that manages the overall PDF processing pipeline
- **Outline Extractor** (`outline_extractor.py`): Specialized component for extracting document structure and headings
- **Table Extractor** (`table_extractor.py`): Dedicated component for detecting and extracting table data
- **Utilities** (`utils.py`): Shared helper functions for text normalization, language detection, and Unicode handling

### Processing Pipeline
1. File validation and directory setup
2. PDF document loading using dual library approach
3. Language detection and text direction analysis
4. Parallel outline and table extraction
5. Data normalization and structure preservation
6. JSON output generation

## Key Components

### PDF Processing Libraries
- **PyMuPDF (fitz)**: Primary library for outline extraction and document metadata
- **pdfplumber**: Secondary library specialized for table detection and extraction
- **Dual Library Strategy**: Uses both libraries to maximize extraction accuracy through different strengths

### Multilingual Text Processing
- **Unicode Normalization**: NFC (Canonical Decomposition followed by Canonical Composition) for consistent character representation
- **Text Direction Detection**: Automatic detection of LTR, RTL, and mixed text directions
- **Language-Specific Patterns**: Regex patterns tailored for different writing systems (Latin, Arabic, CJK)

### Outline Extraction Engine
- **Heading Hierarchy Detection**: Identifies H1, H2, H3 structure through font analysis and pattern matching
- **Multi-Strategy Approach**: Font-based detection, pattern matching, and fallback methods
- **Confidence Scoring**: Minimum threshold system (0.6) for heading classification

### Table Extraction Engine
- **Structure Preservation**: Maintains table layout, headers, and cell relationships
- **Configurable Detection**: Fine-tuned parameters for line detection, tolerance, and text alignment
- **Validation System**: Minimum row/column requirements (2x2) to filter out false positives

## Data Flow

1. **Input Validation**: Verify PDF files exist and are readable
2. **Document Loading**: Open files with both PyMuPDF and pdfplumber
3. **Language Analysis**: Detect primary language and text direction
4. **Concurrent Extraction**: 
   - Outline extraction using font analysis and pattern matching
   - Table extraction using grid detection algorithms
5. **Data Normalization**: Unicode normalization and text cleaning
6. **Structure Assembly**: Combine outline and table data into unified format
7. **Output Generation**: JSON format with preserved structure and metadata

## External Dependencies

### Core Libraries
- **PyMuPDF (fitz)**: PDF manipulation and text extraction
- **pdfplumber**: Advanced table detection and layout analysis

### Python Standard Library
- **pathlib**: Modern file path handling
- **unicodedata**: Unicode character analysis and normalization
- **logging**: Comprehensive logging system
- **json**: Output formatting
- **re**: Pattern matching for heading detection

### System Requirements
- Python 3.7+ (for pathlib and modern Unicode support)
- Cross-platform compatibility (Windows, macOS, Linux)

## Deployment Strategy

### Docker Containerization (Production Ready)
- **Dockerfile**: Complete containerization for CPU-only amd64 environments
- **No Internet Access**: Runs with `--network none` flag for security
- **Small Footprint**: Optimized image size under 200MB requirement
- **Volume Mapping**: Input/output directories mapped via Docker volumes
- **Build Scripts**: Automated build (`build_docker.sh`) and test (`test_docker.sh`) scripts
- **Security**: Non-root user execution inside container

### Local Development
- Simple pip-based installation
- No external services or databases required
- Command-line interface for easy integration

### Batch Processing Support
- Input/output directory structure
- Progress logging and error handling
- Scalable for large document collections

### Performance Optimization
- Page limit configuration (default 50 pages)
- Memory-efficient processing
- Fast processing target (under 10 seconds per PDF)
- CPU-only processing (no GPU dependencies)

### Error Handling
- Graceful degradation when extraction fails
- Comprehensive logging for debugging
- Fallback strategies for different PDF formats

### Container Usage
```bash
# Build and run
./build_docker.sh
docker run --rm -v $(pwd)/input:/app/input -v $(pwd)/output:/app/output --network none mysolution:latest
```

The architecture prioritizes modularity, multilingual support, and processing speed while maintaining extraction accuracy across diverse document types and languages.
